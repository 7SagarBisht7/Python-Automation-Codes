{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lkOVMxLL8WI_",
        "outputId": "f3519590-e86e-43f9-f26a-cd71044baa9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scrapy in /usr/local/lib/python3.12/dist-packages (2.14.1)\n",
            "Requirement already satisfied: cryptography>=37.0.0 in /usr/local/lib/python3.12/dist-packages (from scrapy) (43.0.3)\n",
            "Requirement already satisfied: cssselect>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from scrapy) (1.3.0)\n",
            "Requirement already satisfied: defusedxml>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from scrapy) (0.7.1)\n",
            "Requirement already satisfied: itemadapter>=0.1.0 in /usr/local/lib/python3.12/dist-packages (from scrapy) (0.13.1)\n",
            "Requirement already satisfied: itemloaders>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from scrapy) (1.3.2)\n",
            "Requirement already satisfied: lxml>=4.6.4 in /usr/local/lib/python3.12/dist-packages (from scrapy) (6.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from scrapy) (25.0)\n",
            "Requirement already satisfied: parsel>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from scrapy) (1.10.0)\n",
            "Requirement already satisfied: protego>=0.1.15 in /usr/local/lib/python3.12/dist-packages (from scrapy) (0.5.0)\n",
            "Requirement already satisfied: pydispatcher>=2.0.5 in /usr/local/lib/python3.12/dist-packages (from scrapy) (2.0.7)\n",
            "Requirement already satisfied: pyopenssl>=22.0.0 in /usr/local/lib/python3.12/dist-packages (from scrapy) (24.2.1)\n",
            "Requirement already satisfied: queuelib>=1.4.2 in /usr/local/lib/python3.12/dist-packages (from scrapy) (1.8.0)\n",
            "Requirement already satisfied: service-identity>=18.1.0 in /usr/local/lib/python3.12/dist-packages (from scrapy) (24.2.0)\n",
            "Requirement already satisfied: tldextract in /usr/local/lib/python3.12/dist-packages (from scrapy) (5.3.1)\n",
            "Requirement already satisfied: twisted<=25.5.0,>=21.7.0 in /usr/local/lib/python3.12/dist-packages (from scrapy) (25.5.0)\n",
            "Requirement already satisfied: w3lib>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from scrapy) (2.3.1)\n",
            "Requirement already satisfied: zope-interface>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from scrapy) (8.2)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=37.0.0->scrapy) (2.0.0)\n",
            "Requirement already satisfied: jmespath>=0.9.5 in /usr/local/lib/python3.12/dist-packages (from itemloaders>=1.0.1->scrapy) (1.0.1)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.12/dist-packages (from service-identity>=18.1.0->scrapy) (25.4.0)\n",
            "Requirement already satisfied: pyasn1 in /usr/local/lib/python3.12/dist-packages (from service-identity>=18.1.0->scrapy) (0.6.1)\n",
            "Requirement already satisfied: pyasn1-modules in /usr/local/lib/python3.12/dist-packages (from service-identity>=18.1.0->scrapy) (0.4.2)\n",
            "Requirement already satisfied: automat>=24.8.0 in /usr/local/lib/python3.12/dist-packages (from twisted<=25.5.0,>=21.7.0->scrapy) (25.4.16)\n",
            "Requirement already satisfied: constantly>=15.1 in /usr/local/lib/python3.12/dist-packages (from twisted<=25.5.0,>=21.7.0->scrapy) (23.10.4)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in /usr/local/lib/python3.12/dist-packages (from twisted<=25.5.0,>=21.7.0->scrapy) (21.0.0)\n",
            "Requirement already satisfied: incremental>=24.7.0 in /usr/local/lib/python3.12/dist-packages (from twisted<=25.5.0,>=21.7.0->scrapy) (24.11.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.12/dist-packages (from twisted<=25.5.0,>=21.7.0->scrapy) (4.15.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from tldextract->scrapy) (3.11)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from tldextract->scrapy) (2.32.4)\n",
            "Requirement already satisfied: requests-file>=1.4 in /usr/local/lib/python3.12/dist-packages (from tldextract->scrapy) (3.0.1)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.12/dist-packages (from tldextract->scrapy) (3.20.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=37.0.0->scrapy) (2.23)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.1.0->tldextract->scrapy) (3.4.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.1.0->tldextract->scrapy) (2026.1.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install scrapy\n",
        "\n",
        "#Exception handling using safe selectors of scrapy\n",
        "import scrapy\n",
        "\n",
        "class SafeSelectorSpider(scrapy.Spider):\n",
        "    name = \"safe_selector\"\n",
        "    start_urls = [\"https://quotes.toscrape.com/\"]\n",
        "\n",
        "    def parse(self, response):\n",
        "        for quote in response.css(\"div.quote\"):\n",
        "            # Safe extraction with defaults\n",
        "            text = quote.css(\"span.text::text\").get(default=\"Text not available\")\n",
        "            author = quote.css(\"small.author::text\").get(default=\"Author not available\")\n",
        "\n",
        "            tags = quote.css(\"a.tag::text\").getall()\n",
        "            first_tag = tags[0] if tags else \"No tags\"\n",
        "\n",
        "            yield {\n",
        "                \"quote\": text,\n",
        "                \"author\": author,\n",
        "                \"first_tag\": first_tag\n",
        "            }"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#using try except\n",
        "import scrapy\n",
        "\n",
        "class WithExceptionSpider(scrapy.Spider):\n",
        "    name = \"with_exception\"\n",
        "    start_urls = [\"https://quotes.toscrape.com/\"]\n",
        "\n",
        "    def parse(self, response):\n",
        "        for quote in response.css(\"div.quote\"):\n",
        "            text = quote.css(\"span.text::text\").get()\n",
        "            try:\n",
        "                first_word = text.split()[0]\n",
        "            except (AttributeError, IndexError):\n",
        "                first_word = \"N/A\"\n",
        "\n",
        "            try:\n",
        "                quote_length = len(text)\n",
        "            except TypeError:\n",
        "                quote_length = 0\n",
        "\n",
        "            yield {\n",
        "                \"quote\": text if text else \"Text not available\",\n",
        "                \"first_word\": first_word,\n",
        "                \"length\": quote_length\n",
        "            }"
      ],
      "metadata": {
        "id": "KEW8cd9G9rHr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}